{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34050230",
   "metadata": {},
   "source": [
    "## Identifying Inconsistencies and Cleaning Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212bfa46",
   "metadata": {},
   "source": [
    "###### Loading the Customer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b95f6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset (delimited text file)\n",
    "data = pd.read_csv(\"C:\\dataset\\customer_data.txt\", delimiter=',')  # Adjust delimiter if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c1700",
   "metadata": {},
   "source": [
    "###### Part 1: Identify all inconsistencies in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b7a42e",
   "metadata": {},
   "source": [
    ">  By running the below checks, one can identify inconsistencies like \n",
    "\n",
    "-  Missing values\n",
    "\n",
    "- Invalid data types\n",
    "\n",
    "- Outliers\n",
    "\n",
    "- Duplicate rows\n",
    "\n",
    "- nconsistencies in text\n",
    "\n",
    "- logical relationships across columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d6451",
   "metadata": {},
   "source": [
    "###### Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1691ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custID               0\n",
      "custName             1\n",
      "Age                  7\n",
      "Product              1\n",
      "DatePurchased        7\n",
      "Price                4\n",
      "RatingOfProduct      7\n",
      "AdvertisingAgency    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identifying for missing values\n",
    "missing_data = data.isnull().sum()\n",
    "print(missing_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64ff17",
   "metadata": {},
   "source": [
    "- After identifying the missing values then dropping and filling missing values\n",
    "\n",
    "- Dropping rows with missing values.\n",
    "\n",
    "- Filling missing values with mean/median/mode for numerical columns or a placeholder for categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b679747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Fill missing values in the 'RatingOfProduct' column with the median\n",
    "data['RatingOfProduct'].fillna(data['RatingOfProduct'].median(), inplace=True)\n",
    "\n",
    "# Example: Fill missing values in 'AdvertisingAgency' with 'Unknown'\n",
    "data['AdvertisingAgency'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbcde6e",
   "metadata": {},
   "source": [
    "###### Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a348030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicate rows\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Removing duplicate rows\n",
    "data.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d3c7d",
   "metadata": {},
   "source": [
    "###### Ensure Data Types are Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "499b1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'DatePurchased' to datetime format\n",
    "data['DatePurchased'] = pd.to_datetime(data['DatePurchased'], errors='coerce')\n",
    "\n",
    "# Ensure 'Price' and 'RatingOfProduct' are numerical\n",
    "data['Price'] = pd.to_numeric(data['Price'], errors='coerce')\n",
    "data['RatingOfProduct'] = pd.to_numeric(data['RatingOfProduct'], errors='coerce')\n",
    "\n",
    "# Ensure 'Age' is integer\n",
    "data['Age'] = pd.to_numeric(data['Age'], downcast='integer', errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae99d3a",
   "metadata": {},
   "source": [
    "###### Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6b06c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [custID, custName, Age, Product, DatePurchased, Price, RatingOfProduct, AdvertisingAgency]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Identifying outliers in 'Price'\n",
    "import numpy as np\n",
    "\n",
    "price_outliers = data[(data['Price'] > data['Price'].mean() + 3 * data['Price'].std()) |\n",
    "                      (data['Price'] < data['Price'].mean() - 3 * data['Price'].std())]\n",
    "\n",
    "print(price_outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9470757b",
   "metadata": {},
   "source": [
    "###### Standardize the Format of Text Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30f8b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading/trailing spaces and standardize text columns to lower case\n",
    "data['custName'] = data['custName'].str.strip().str.title()\n",
    "data['Product'] = data['Product'].str.strip().str.title()\n",
    "data['AdvertisingAgency'] = data['AdvertisingAgency'].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db2058",
   "metadata": {},
   "source": [
    "###### Handle Invalid Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a45744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading/trailing spaces and standardize text columns to lower case\n",
    "data['custName'] = data['custName'].str.strip().str.title()\n",
    "data['Product'] = data['Product'].str.strip().str.title()\n",
    "data['AdvertisingAgency'] = data['AdvertisingAgency'].str.strip().str.title()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e6ac4a",
   "metadata": {},
   "source": [
    "###### Final Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ee117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   custID             100 non-null    int64         \n",
      " 1   custName           99 non-null     object        \n",
      " 2   Age                93 non-null     float64       \n",
      " 3   Product            99 non-null     object        \n",
      " 4   DatePurchased      93 non-null     datetime64[ns]\n",
      " 5   Price              96 non-null     float64       \n",
      " 6   RatingOfProduct    100 non-null    float64       \n",
      " 7   AdvertisingAgency  100 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(3)\n",
      "memory usage: 7.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining issues\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9484e14",
   "metadata": {},
   "source": [
    "###### Export the Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "664335c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data to a new CSV file\n",
    "data.to_csv('cleaned_customer_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1b904",
   "metadata": {},
   "source": [
    "###### Part 2: Discuss in detail the FIVE techniques/methods you can use to solve the inconsistencies identified in Part 1. How can you ensure that data is correctly captured during data collection? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7b37d",
   "metadata": {},
   "source": [
    "Techniques to Solve Data Inconsistencies\n",
    "\n",
    "*Handling Missing Values*\n",
    "\n",
    "- Imputation: Replace missing values with calculated estimates like the mean, median, or mode, or by using advanced methods like machine learning.\n",
    "\n",
    "- Removal: In cases where too many values are missing, remove the rows or columns altogether.\n",
    "\n",
    "\n",
    "*Data Collection Measures*\n",
    "\n",
    "- Use real-time validation to ensure mandatory fields are filled, and provide sensible default values where applicable.\n",
    "\n",
    "*Correcting Inconsistent Data Types*\n",
    "\n",
    "- Convert columns to appropriate data types (e.g., numeric or date) to ensure proper analysis.\n",
    "\n",
    "- Handle errors by flagging or removing invalid data entries.\n",
    "\n",
    "*Data Collection Measures*\n",
    "\n",
    "- Implement formatting restrictions for input fields, and validate data types as part of the collection process.\n",
    "\n",
    "*Removing Duplicates*\n",
    "\n",
    "- Identify and remove duplicate entries to ensure accuracy in data analysis.\n",
    "\n",
    "- Use unique identifiers to prevent duplicate data from being recorded.\n",
    "\n",
    "*Data Collection Measures*\n",
    "\n",
    "- Assign unique IDs to records and implement real-time duplicate detection to avoid redundant data entry.\n",
    "\n",
    "*Correcting Invalid or Out-of-Range Values*\n",
    "\n",
    "- Filter out or flag values that fall outside acceptable ranges, such as outliers in numerical fields.\n",
    "- Use range checks to maintain consistency.\n",
    "\n",
    "*Data Collection Measures*\n",
    "\n",
    "- Set constraints for data entry (e.g., limiting numeric values to valid ranges) and provide real-time alerts for invalid inputs.\n",
    "\n",
    "*Standardizing Inconsistent Text Entries*\n",
    "\n",
    "- Normalize text by ensuring consistent formats (e.g., case consistency) and remove extra spaces.\n",
    "\n",
    "- Use dictionary mapping to standardize common variations in text entries.\n",
    "\n",
    "*Data Collection Measures*\n",
    "\n",
    "- Use dropdowns or selection lists instead of free-form text fields to avoid variations, and apply automatic formatting for consistent data entry.\n",
    "\n",
    "- Ensuring Correct Data Capture\n",
    "\n",
    "*To ensure data is accurately captured during collection*\n",
    "\n",
    "- Automated Data Validation: Ensure all fields follow the correct format and rules during data entry.\n",
    "\n",
    "- Pre-Defined Input Formats: Use tools like dropdowns, date pickers, and masked fields to limit errors.\n",
    "\n",
    "- Unique Identifiers: Assign unique IDs for each entry to prevent duplicates.\n",
    "\n",
    "- Training: Provide proper training for data entry personnel to follow standard protocols.\n",
    "\n",
    "- Auditing: Regularly audit and monitor the data collection process to catch and correct errors early.\n",
    "\n",
    "These techniques and safeguards will address inconsistencies and help ensure reliable, high-quality data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe432fee",
   "metadata": {},
   "source": [
    "###### Part 4: Discuss any FIVE potential challenges and FIVE opportunities that a company using this dataset will potentially experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f0743",
   "metadata": {},
   "source": [
    "*Challenges a Company Using This Dataset May Experience* \n",
    "\n",
    "Data Quality Issues:\n",
    "Poor data quality, such as missing or incorrect values, duplicates, and inconsistencies, can limit the accuracy of insights drawn from the dataset. For instance, if customer names or product details are incomplete or duplicated, it could lead to flawed analyses and decisions.\n",
    "\n",
    "Data Integration Difficulties:\n",
    "Integrating this dataset with other systems (e.g., customer relationship management (CRM) or enterprise resource planning (ERP)) might be challenging, especially if the formats are incompatible. Data inconsistencies such as varying formats for dates or product names can make it difficult to merge datasets effectively.\n",
    "\n",
    "Privacy and Compliance Risks:\n",
    "Storing and using customer data, particularly sensitive information like purchasing history and demographic details, introduces privacy concerns. If not properly managed, it could lead to violations of regulations like GDPR or CCPA, resulting in fines or reputational damage.\n",
    "\n",
    "Data Overload and Complexity:\n",
    "The volume of data generated can be overwhelming, particularly for a company that is not equipped with the right tools for data processing and analysis. Without proper filtering and data governance, it becomes challenging to extract actionable insights from the data.\n",
    "\n",
    "Maintaining Data Freshness:\n",
    "If the dataset is not regularly updated, the company could be working with outdated information. Customer behaviors and product performance can change quickly, so old data may lead to poor decisions if not refreshed.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb1ab3",
   "metadata": {},
   "source": [
    "*Opportunities a Company Using This Dataset May Experience*\n",
    "\n",
    "Improved Customer Segmentation:\n",
    "With detailed purchasing history, age, and product ratings, the company can segment its customer base more accurately. This allows for targeted marketing campaigns, personalized offers, and better understanding of customer preferences.\n",
    "\n",
    "Enhanced Product Development and Feedback:\n",
    "The product ratings in the dataset provide direct customer feedback, which can be used to improve existing products or guide the development of new ones. High-rated products can be promoted, while low-rated ones may signal the need for improvements.\n",
    "\n",
    "Optimized Marketing Strategies:\n",
    "The presence of advertising agency information along with product purchases provides an opportunity to evaluate the effectiveness of different advertising campaigns. The company can track which agencies or campaigns lead to better sales and focus resources accordingly.\n",
    "\n",
    "Data-Driven Decision Making:\n",
    "By analyzing the dataset, the company can identify trends and patterns that can inform decision-making. For example, they may find that certain products sell better to specific age groups, enabling more precise inventory management and marketing efforts.\n",
    "\n",
    "Personalization and Customer Retention:\n",
    "With customer history available, the company can offer personalized recommendations based on past purchases. This enhances customer satisfaction and increases loyalty, as personalized experiences are often linked to better customer retention.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a4bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
